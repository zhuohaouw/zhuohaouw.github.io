---
layout: publication
year: 2021
title: "WebAlly: Making Visual Task-based CAPTCHAs Transferable for People with Visual Impairments"
authors:
  - Zhuohao Zhang
  - Zhilin Zhang
  - Haolin Yuan
  - Nat√£ Barbosa
  - Sauvik Das
  - Yang Wang
type:
  - Conference
venue: SOUPS
venue_tags:
  - SOUPS
pdf: "https://www.usenix.org/system/files/soups2021-zhang-zhuohao.pdf"
slide: "https://www.usenix.org/system/files/soups2021_slides_zhang_zhuohao.pdf"
recording: "https://www.youtube.com/watch?v=RMqrhzlc2us"
highlight: true
---

Collaborative document editing tools are widely used in professional and academic workplaces. While these tools provide basic accessibility support, it is challenging for blind users to gain collaboration awareness that sighted people can easily obtain using visual cues (e.g., who is editing where and what). Through a series of co-design sessions with a blind coauthor, we identified concrete challenges of blind people using collaborative editing, and iteratively designed CollabAlly, a system that makes collaboration awareness in document editing accessible to blind users. CollabAlly extracts collaborator, comment, and text-change information and their context from a document and presents them in a dialog box to provide easy access and navigation. CollabAlly uses earcons to communicate background events unobtrusively, voice fonts to differentiate collaborators, and spatial audio to convey the location of document activity. In a study with 11 blind participants, we demonstrate that CollabAlly provides improved access to collaboration awareness by centralizing scattered information, sonifying visual information, and simplifying complex operations. 