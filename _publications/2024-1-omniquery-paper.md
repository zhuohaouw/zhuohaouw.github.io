---
layout: publication
year: 2024
title: "OmniQuery: Contextually Augmenting Captured Multimodal Memory to Enable Personal Question Answering"
authors:
  - Jiahao Li
  - Zhuohao Zhang
  - Jiaju Ma
pdf: "https://arxiv.org/pdf/2409.08250"
---

People often capture memories through photos, screenshots, and
videos. While existing AI-based tools enable querying this data us-
ing natural language, they mostly only support retrieving individual
pieces of information like certain objects in photos, and struggle
with answering more complex queries that involve interpreting
interconnected memories like event sequences. We conducted a one-
month diary study to collect realistic user queries and generated
a taxonomy of necessary contextual information for integrating
with captured memories. We then introduce OmniQuery, a novel
system that is able to answer complex personal memory-related
questions that require extracting and inferring contextual infor-
mation. OmniQuery augments single captured memories through
integrating scattered contextual information from multiple inter-
connected memories, retrieves relevant memories, and uses a large
language model (LLM) to comprehensive answers. In human evalu-
ations, we show the effectiveness of OmniQuery with an accuracy
of 71.5% and it outperformed a conventional RAG system, winning
or tying in 74.5% of the time.